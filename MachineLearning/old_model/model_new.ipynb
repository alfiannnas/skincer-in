{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52c9a98f",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fb3060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "import math\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4aa63f",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca31036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting data from zip\n",
    "local_zip = './data/archive_data/new_dataset.zip'\n",
    "target_extraction = './data/data_2'\n",
    "file_check = \"ISIC_Labelled\"\n",
    "\n",
    "try:\n",
    "    if os.path.exists(os.path.join(target_extraction, file_check)):\n",
    "        print(\"File Already Extracted\")\n",
    "    else:\n",
    "        zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "        zip_ref.extractall(target_extraction)\n",
    "        zip_ref.close()\n",
    "#if data is already extracted it will instead print file already extracted\n",
    "except FileNotFoundError:\n",
    "    print('Zip File Not Found!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162fcefd",
   "metadata": {},
   "source": [
    "# Check Data and Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3751ec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './data/data_2/ISIC_Labelled'\n",
    "file = []\n",
    "for files in os.walk(root, topdown=True):\n",
    "    file.append(files)\n",
    "    \n",
    "ffile = file[1:]\n",
    "file = []\n",
    "counter = 0\n",
    "for x in ffile:\n",
    "    counter += len(x[2])\n",
    "\n",
    "print(f\"there is {counter} data in data_2\")\n",
    "tumor_2 = len(os.listdir(root))\n",
    "print(f\"with {tumor_2} classifications\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b3c77d",
   "metadata": {},
   "source": [
    "# Create Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24f2651",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_2 = ['melanoma', 'melanocytic_nevi', 'basal_cell_carcinoma', 'bowen_disease', 'benign_keratosis', 'dermatofibroma', 'vascular_lesions', 'squamous_cell_carcinoma']\n",
    "root_dir = \"./data/final_dataset\"\n",
    "file_check = \"Training\"\n",
    "def create_dir(root_path):\n",
    "    \n",
    "    try:\n",
    "        if os.path.exists(os.path.join(root_dir, file_check)):\n",
    "            for it in os.scandir(root_dir):\n",
    "                if it.is_dir():\n",
    "                    print(it.path)\n",
    "            print(\"File Already Created!\")\n",
    "        else:\n",
    "            if os.path.exists(root_dir):\n",
    "                shutil.rmtree(root_dir)\n",
    "\n",
    "            os.makedirs(os.path.join(root_path, 'training'))\n",
    "            os.makedirs(os.path.join(root_path, 'validation'))\n",
    "\n",
    "\n",
    "            for i in dir_2:\n",
    "                os.makedirs(os.path.join(f'{root_path}/training', i))\n",
    "                os.makedirs(os.path.join(f'{root_path}/validation', i))\n",
    "\n",
    "            print(\"Folder Created!\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f'An error occurred: {str(e)}')\n",
    "\n",
    "            \n",
    "create_dir(root_path=root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e754cf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_paths = []\n",
    "val_paths = []\n",
    "for class_name in dir_new:\n",
    "    training_path = os.path.join(training_main, class_name)\n",
    "    val_path = os.path.join(validation_main, class_name)\n",
    "    training_paths.append(training_path)\n",
    "    val_paths.append(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bebe0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, class_path in enumerate (training_paths):\n",
    "    print(class_path)\n",
    "print('\\n')\n",
    "for i, class_path in enumerate (val_paths):\n",
    "    print(class_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de99f7b",
   "metadata": {},
   "source": [
    "# Specific Name Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61836981",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/data_2/ISIC_Labelled'\n",
    "\n",
    "dir_new = ['melanoma', 'melanocytic_nevi', 'basal_cell_carcinoma', 'bowen_disease', 'benign_keratosis', 'dermatofibroma', 'vascular_lesions', 'squamous_cell_carcinoma']\n",
    "dir_old = ['Melanoma', 'Melanocytic nevus', 'Basal cell carcinoma', 'Actinic keratosis', 'Benign keratosis', 'Dermatofibroma', 'Vascular lesion', 'Squamous cell carcinoma']\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    file_path = os.path.join(path, filename)\n",
    "    name = os.path.splitext(filename)\n",
    "    \n",
    "    for i, x in enumerate(dir_old):\n",
    "        if x in name:\n",
    "            postfix = dir_new[i]\n",
    "            new_name = os.path.join(path, postfix)\n",
    "            os.rename(file_path, new_name)\n",
    "            continue\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bbf4ff",
   "metadata": {},
   "source": [
    "# Split our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1429bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for file in (dir_2):\n",
    "    dir = os.listdir(f\"{path}/{file}\")\n",
    "    random.shuffle(dir)\n",
    "    \n",
    "    training = dir[:200]\n",
    "    val = dir[200:239]\n",
    "    print(f\"Training data for {file} is {len(training)}\")\n",
    "    print(f\"Validation data for {file} is {len(val)}\\n\")\n",
    "    \n",
    "    root = './data/data_2/ISIC_Labelled/'\n",
    "    root_dest = './data/final_dataset'\n",
    "    for i in training:\n",
    "        source_img = os.path.join(f\"{root}/{dir_2[counter]}\", i)\n",
    "        destination = os.path.join(f\"{root_dest}/training/{dir_2[counter]}\", i)\n",
    "        copyfile(source_img, destination)\n",
    "    \n",
    "    for i in val:\n",
    "        source_img = os.path.join(f\"{root}/{dir_2[counter]}\", i)\n",
    "        destination = os.path.join(f\"{root_dest}/validation/{dir_2[counter]}\", i)\n",
    "        copyfile(source_img, destination)\n",
    "        \n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8f7c11",
   "metadata": {},
   "source": [
    "# Set Directory Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d76d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_main = './data/final_dataset/training'\n",
    "validation_main = './data/final_dataset/validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aacae15",
   "metadata": {},
   "source": [
    "# Visualize and Plot the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e99fff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show image example\n",
    "root_path = './data/final_dataset/training/'\n",
    "fig, axes = plt.subplots(2, 4, figsize=(15,5))\n",
    "counter = 0\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        ax = axes[i][j]\n",
    "        ax.set_title(dir_new[counter])\n",
    "        ax.imshow(load_img(f\"{os.path.join(f'{root_path}/{dir_new[counter]}', os.listdir(f'{root_path+dir_new[counter]}')[random.randint(0,100)])}\"))\n",
    "        ax.set_axis_off()\n",
    "        plt.show\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e09a31c",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf2a1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_generators(training_main, validation_main):\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255.,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        directory=training_main,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=64,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(rescale=1./255.)\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        directory=validation_main,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311133e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, validation_generator = train_val_generators(training_main, validation_main)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9f5e1b",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d882de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Dense(8, activation='softmax')\n",
    "  ])\n",
    "  \n",
    "\n",
    "    model.compile(optimizer = tf.optimizers.Adam(),\n",
    "                loss = 'categorical_crossentropy',\n",
    "                metrics=['accuracy'])       \n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f681ca",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa32ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779a2c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988b60ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Train your model\n",
    "history = model.fit(train_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bf8574",
   "metadata": {},
   "source": [
    "# Create Model using VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694ff448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c910701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vgg = VGG16(include_top=False, input_shape = (150,150,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a200ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "## Loading VGG16 model\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(150,150,3))\n",
    "base_model.trainable = False ## Not trainable weights\n",
    "\n",
    "## Preprocessing input\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01246631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "es = EarlyStopping(monitor='accuracy', mode='max', patience=5,  restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0246ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "        # Define the correct function signature for on_epoch_end\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            if logs.get('accuracy') is not None and logs.get('accuracy') > 0.90: # @KEEP\n",
    "                print(\"\\nReached 99% accuracy so cancelling training!\") \n",
    "                \n",
    "                # Stop training once the above condition is met\n",
    "                self.model.stop_training = True\n",
    "                \n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d921db0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "tf.random.set_seed(33)\n",
    "def create_model():\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAvgPool2D(),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(62, activation='relu'),\n",
    "    tf.keras.layers.Dense(8, activation='softmax')\n",
    "  ])\n",
    "  \n",
    "\n",
    "    model.compile(optimizer = tf.optimizers.SGD(learning_rate=0.0001),\n",
    "                loss = 'categorical_crossentropy',\n",
    "                metrics=['accuracy'])       \n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7363c7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model.fit(train_generator, validation_data=validation_generator, validation_steps=int(0.15*len(validation_generator)),epochs = 50, batch_size = 32, callbacks=[reduce_lr, callbacks])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85ab0df",
   "metadata": {},
   "source": [
    "# Create Model using MobilenetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a15ccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.random.set_seed(42)\n",
    "# base_model = tf.keras.applications.MobileNetV2(include_top=False)\n",
    "# base_model.trainable= False\n",
    "\n",
    "# inputs = tf.keras.layers.Input(shape=(150,150,3),name = \"input_shape\",dtype=tf.float16)\n",
    "# x = base_model(inputs,training=False)\n",
    "# x = tf.keras.layers.GlobalAvgPool2D(name=\"global_average_pooling_layer\")(x)\n",
    "# outputs = tf.keras.layers.Dense(8,activation='softmax',dtype=tf.float32,name='outputs')(x)\n",
    "\n",
    "# model_2 = Model(inputs,outputs)\n",
    "\n",
    "# model_2.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "\n",
    "# model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91459602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history2 = model_2.fit(train_generator, validation_data=validation_generator, validation_steps=int(0.15*len(validation_generator)),epochs = 20, batch_size = 32, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ccde20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
